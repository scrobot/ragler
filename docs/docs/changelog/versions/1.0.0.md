---
sidebar_position: 1
title: Version 1.0.0
---

# RAGler v1.0.0

**Release Date:** February 8, 2026
**Type:** Major Release (Initial Public Release)

## Overview

RAGler v1.0.0 is the first public release of the RAGler Knowledge Management System for RAG (Retrieval-Augmented Generation). This release provides a complete, production-ready platform for Human-in-the-Loop knowledge curation.

## Highlights

âœ¨ **Human-in-the-Loop Workflow** â€” Edit and validate chunks before publishing
ðŸ”„ **Atomic Replacement** â€” Clean content updates with no duplicates
ðŸ“Š **Three Data Sources** â€” Confluence, Web URLs, and Manual input
ðŸ‘¥ **Role-Based Access** â€” Simple Mode for L2 Support, Advanced Mode for Developers/ML
ðŸŽ¯ **Collection Management** â€” Organize knowledge by context and audience
ðŸ¤– **LLM-Powered Chunking** â€” GPT-4o for intelligent semantic chunking

## Core Features

### Data Ingestion

- **Confluence Integration** â€” Import pages via URL with API authentication
- **Web Scraping** â€” Extract content from public URLs with HTMLâ†’Markdown conversion
- **Manual Input** â€” Direct text entry for custom content
- **Automatic Chunking** â€” LLM-based semantic splitting using GPT-4o
- **Source Tracking** â€” MD5 source_id for atomic replacement

### Draft Sessions

- **Redis-Based Sessions** â€” Ephemeral editing sandbox with 24-hour TTL
- **Session States** â€” DRAFT â†’ LOCKED â†’ PUBLISHED lifecycle
- **Chunk Editing** â€” Modify content before publishing
- **Preview Mode** â€” Validate chunks with locking mechanism
- **Session Management** â€” List, view, and discard draft sessions

### Chunk Operations (Advanced Mode)

- **Split Chunks** â€” Divide chunks at semantic boundaries
- **Merge Chunks** â€” Combine related chunks into one
- **Reorder Chunks** â€” Adjust chunk sequence
- **LLM Assistant** â€” Scenarios for simplifying, clarifying, and enriching content

### Collections

- **Dynamic Collections** â€” Create collections via API (no hardcoded domains)
- **Collection Registry** â€” Stored in Qdrant `sys_registry` collection
- **Purpose-Driven Organization** â€” Collections describe context and audience
- **Collection Metadata** â€” Name, description, purpose, creator, timestamps

### Publishing

- **Atomic Replacement** â€” Delete-Insert strategy prevents duplicates
- **Embedding Generation** â€” OpenAI text-embedding-3-small (1536 dimensions)
- **Mandatory Collection Selection** â€” Cannot publish without target collection
- **Batch Processing** â€” Configurable batch size for embeddings (default: 100)

### Role-Based Access Control

**Simple Mode (L2 Support):**
- View and edit chunk content
- Use LLM assistant scenarios
- Publish to existing collections
- Cannot split/merge chunks or create collections

**Advanced Mode (Developers, ML Specialists):**
- All Simple Mode capabilities
- Split and merge chunks
- Create and delete collections
- Bulk operations (future)

### API

- **REST API** â€” NestJS backend with OpenAPI documentation
- **Authentication Headers** â€” `X-User-ID` and `X-User-Role` (trusted headers for MVP)
- **Rate Limiting** â€” Configurable throttling (default: 100 req/min)
- **Health Checks** â€” `/health/live` and `/health/ready` endpoints
- **Swagger UI** â€” Interactive API documentation at `/api/docs`

### Infrastructure

- **Backend** â€” Node.js 20+ with NestJS framework
- **Frontend** â€” Next.js 18 with Metronic UI (optional)
- **Redis** â€” Session storage (ephemeral)
- **Qdrant** â€” Vector database for published chunks
- **OpenAI** â€” GPT-4o (chunking), GPT-4o-mini (enrichment), text-embedding-3-small (vectors)
- **Docker Compose** â€” Infrastructure setup with Redis + Qdrant

### Observability

- **Structured Logging** â€” JSON logs with correlation IDs (request_id, session_id, user_id, source_id)
- **Key Events** â€” ingest_start, chunking_success, publish_start, publish_success, etc.
- **Error Handling** â€” Consistent error response format
- **Metrics-Ready** â€” Prometheus-compatible log format (metrics integration future)

## Architecture Decisions (ADRs)

This release implements the following architectural decisions:

1. **ADR-001: Vector-Only Storage** â€” No SQL database; all data in Qdrant or Redis
2. **ADR-002: Atomic Replacement** â€” Delete-Insert strategy for clean updates
3. **ADR-003: Two-LLM Pattern** â€” GPT-4o for chunking, GPT-4o-mini for enrichment
4. **ADR-004: Dynamic Collections** â€” Collections managed via API, stored in Qdrant

See [Architecture Decision Records](/docs/architecture/adr) for details.

## API Endpoints

### Collections

- `GET /api/collections` â€” List all collections
- `GET /api/collections/:id` â€” Get collection by ID
- `POST /api/collections` â€” Create collection (DEV/ML only)
- `DELETE /api/collections/:id` â€” Delete collection (DEV/ML only)

### Ingestion

- `POST /api/ingest` â€” Start ingestion session (all source types)

### Sessions

- `GET /api/sessions` â€” List user's sessions
- `GET /api/sessions/:id` â€” Get session details
- `PATCH /api/sessions/:id/chunks/:chunkId` â€” Edit chunk
- `POST /api/sessions/:id/chunks/:chunkId/split` â€” Split chunk (DEV/ML only)
- `POST /api/sessions/:id/chunks/merge` â€” Merge chunks (DEV/ML only)
- `POST /api/sessions/:id/preview` â€” Lock and validate session
- `POST /api/sessions/:id/publish` â€” Publish to collection
- `DELETE /api/sessions/:id` â€” Discard session

### Health

- `GET /health/live` â€” Liveness probe
- `GET /health/ready` â€” Readiness probe (checks Redis + Qdrant)

## Configuration

### Environment Variables

**Required:**
- `OPENAI_API_KEY` â€” OpenAI API key for LLM operations

**Infrastructure:**
- `REDIS_HOST` â€” Redis hostname (default: localhost)
- `REDIS_PORT` â€” Redis port (default: 6379)
- `QDRANT_URL` â€” Qdrant connection URL (default: http://localhost:6333)

**Optional:**
- `CONFLUENCE_BASE_URL` â€” Atlassian Confluence instance URL
- `CONFLUENCE_USER_EMAIL` â€” Confluence user email
- `CONFLUENCE_API_TOKEN` â€” Confluence API token
- `THROTTLE_TTL` â€” Rate limit window in ms (default: 60000)
- `THROTTLE_LIMIT` â€” Max requests per window (default: 100)

See [Configuration Guide](/docs/getting-started/configuration) for all options.

## Breaking Changes

**Not applicable** â€” This is the initial release.

## Known Limitations (MVP Scope)

The following features are **not included** in v1.0:

- Real-time Confluence synchronization
- Bulk document crawling
- Retrieval quality metrics
- A/B testing of RAG answers
- Automatic chunk quality scoring
- Chunk versioning
- Bulk operations in Simple Mode
- Collection migration (moving chunks between collections)
- Custom chunking algorithms
- Partial updates (always full atomic replacement)

These features may be added in future releases based on user feedback.

## Installation

### Quick Start

```bash
# Clone repository
git clone https://github.com/ragler-oss/ragler.git
cd ragler/backend

# Install dependencies
pnpm install

# Configure environment
cp .env.example .env
# Edit .env and set OPENAI_API_KEY

# Start infrastructure
docker compose up -d redis qdrant

# Start backend
pnpm start:dev
```

See [Installation Guide](/docs/getting-started/installation) for detailed setup.

## Upgrade Guide

**Not applicable** â€” This is the initial release.

Future upgrades will include migration guides here.

## Contributors

RAGler v1.0.0 was developed by:

- **Core Team** â€” System architecture, backend, frontend, documentation
- **Community** â€” Testing, feedback, issue reporting

Special thanks to all contributors who made this release possible!

## What's Next?

Planned for v1.1:

- Search/retrieval endpoint (currently chunks are published but not queryable via API)
- Enhanced LLM assistant scenarios
- Improved chunking quality metrics
- Bulk session operations
- MCP Server implementation (Model Context Protocol)

See [GitHub Issues](https://github.com/ragler-oss/ragler/issues) for the full roadmap.

## Feedback & Support

- **Issues:** [GitHub Issues](https://github.com/ragler-oss/ragler/issues)
- **Discussions:** [GitHub Discussions](https://github.com/ragler-oss/ragler/discussions)
- **Documentation:** [docs.ragler.ai](https://ragler.ai/docs)

## License

RAGler is released under the [MIT License](https://github.com/ragler-oss/ragler/blob/main/LICENSE).

---

**Happy knowledge curation! ðŸŽ‰**

Thank you for choosing RAGler for your RAG knowledge management needs.
